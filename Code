import numpy as np
from keras.applications.vgg16 import VGG16, preprocess_input
from keras.preprocessing import image
from sklearn.preprocessing import normalize
from skimage.feature import local_binary_pattern
import cv2
import os
from scipy.spatial.distance import cdist

class DeepFeatureExtractor:
    def __init__(self):
        self.model = VGG16(weights='imagenet', include_top=True)
        from keras.models import Model
        self.sub_model = Model(inputs=self.model.input, outputs=self.model.get_layer('fc2').output)
    def extract(self, img_path):
        img = image.load_img(img_path, target_size=(224, 224))
        x = image.img_to_array(img)
        x = np.expand_dims(x, axis=0)
        x = preprocess_input(x)
        features = self.sub_model.predict(x).flatten()
        return features

def color_autocorrelogram(img_path, ncolors=64):
    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    img_small = cv2.resize(img, (64,64))
    Z = img_small.reshape((-1,3))
    Z = np.float32(Z)
    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)
    _, labels, centers = cv2.kmeans(Z, ncolors, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)
    quantized = centers[labels.flatten()].reshape(img_small.shape)
    quantized = quantized.astype('uint8')
    quant_flat = quantized.reshape(-1, 3)
    color_hist = np.histogramdd(quant_flat, bins=8, range=[(0,256),(0,256),(0,256)])[0]
    return color_hist.flatten()[:256]

def uniform_lbp(img_path, P=8, R=1):
    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
    lbp = local_binary_pattern(img, P, R, method='uniform')
    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, P*2 + 3), range=(0, P*2 + 2))
    hist = hist.astype('float')/hist.sum()
    if len(hist)<59: hist = np.concatenate([hist, np.zeros(59-len(hist))])
    return hist[:59]

def feature_fusion(deep_feat, color_feat, lbp_feat, weights=[0.5,0.3,0.2]):
    feats = [deep_feat, color_feat, lbp_feat]
    norms = [f/np.linalg.norm(f) if np.linalg.norm(f)!=0 else f for f in feats]
    fused = np.concatenate([w*n for w,n in zip(weights, norms)])
    return fused

def build_feature_library(img_dir):
    extractor = DeepFeatureExtractor()
    feature_db = []
    img_paths = [os.path.join(img_dir, f) for f in os.listdir(img_dir) if f.lower().endswith(('.jpg', '.png'))]
    for img_path in img_paths:
        deep_feat = extractor.extract(img_path)
        color_feat = color_autocorrelogram(img_path)
        lbp_feat = uniform_lbp(img_path)
        fused = feature_fusion(deep_feat, color_feat, lbp_feat)
        feature_db.append({'path': img_path, 'feature': fused})
    return feature_db

def retrieve(query_path, feature_db, top_k=10):
    extractor = DeepFeatureExtractor()
    deep_feat = extractor.extract(query_path)
    color_feat = color_autocorrelogram(query_path)
    lbp_feat = uniform_lbp(query_path)
    fused_q = feature_fusion(deep_feat, color_feat, lbp_feat)
    db_features = np.array([item['feature'] for item in feature_db])
    similarities = 1 - cdist([fused_q], db_features, metric='cosine').flatten()
    top_indices = similarities.argsort()[-top_k:][::-1]
    results = [feature_db[i]['path'] for i in top_indices]
    return results

# Example usage:
if __name__ == "__main__":
    img_dir = r"D:\cbir_project\images"
    feature_db = build_feature_library(img_dir)
    query_img = r"D:\cbir_project\images\1.jpg"  # replace with your own query image path here
    results = retrieve(query_img, feature_db, top_k=5)
    print("Top retrieved images:")
    for r in results:
        print(r)


import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# List of image paths to display
image_files = [
    r"D:\cbir_project\images\1.jpg",    # Query image
    r"D:\cbir_project\images\11.jpg",   # Top result 1
    r"D:\cbir_project\images\17.jpg",   # Top result 2
    r"D:\cbir_project\images\5.jpg",    # Top result 3
    r"D:\cbir_project\images\12.jpg",   # Top result 4
]

titles = ['Query', '1st', '2nd', '3rd', '4th']

plt.figure(figsize=(18, 4))

for idx, img_path in enumerate(image_files):
    img = mpimg.imread(img_path)
    plt.subplot(1, 5, idx+1)
    plt.imshow(img)
    plt.title(titles[idx])
    plt.axis('off')

plt.tight_layout()
plt.show()
